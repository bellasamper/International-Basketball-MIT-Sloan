{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7fc3e2-4420-48e9-ba2e-1be46c647ea3",
   "metadata": {},
   "source": [
    "# Full Autostats Exploration (step one) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906a0da-3f89-489e-a97b-ed31d6dada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LassoCV\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import imblearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8dabb0-d675-406e-80e8-63c4152e520d",
   "metadata": {},
   "source": [
    "## Data Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4118a65-f87e-4823-a422-9bf1d0532b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the NBA caliber players\n",
    "nba_players = pd.read_csv(\"NBA Caliber Players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e76245-0515-41b1-8955-2108cdbda7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to drop all start seasons before 2012 since autostats data does not go that far \n",
    "# nba_players = nba_players[nba_players['START_SEASON'] >= 2012].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df61d77-0e76-4b6a-aac7-aad2ab95d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "## giving those players who were not drafted but were still in the NBA a value \n",
    "nba_players['PICK_NUMBER'] = nba_players['PICK_NUMBER'].fillna('Undrafted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cb48f-a7cd-402f-b951-3d01970d49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## autostats data \n",
    "autostats_pct = pd.read_csv('AutoStats Data for Tableau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68e572-912c-457b-be3d-821861c4b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841a9b2-b50e-45de-9e9b-170544124370",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Player ID','Season','AutoStats Games', 'League ID','Offensive Points/Chance',\n",
    "'Defensive Points/Chance',\n",
    "'Offensive Transition%',\n",
    "'Defensive Transition%',\n",
    "'Touches/Chance',\n",
    "'Points/Touch',\n",
    "'Transition Touch%',\n",
    "'Transition Points/Touch',\n",
    "'AutoStats FG%',\n",
    "'AutoStats 3P%',\n",
    "'Contested Jumper FG%',\n",
    "'Uncontested Jumper FG%',\n",
    "'% of Jumpers Contested',\n",
    "'Contested 3P%',\n",
    "'Uncontested 3P%',\n",
    "'% of 3s Contested',\n",
    "'Off Dribble Jumper FG%',\n",
    "'Catch & Shoot Jumper FG%',\n",
    "'Off Dribble 3P%',\n",
    "'Catch & Shoot 3P%',\n",
    "'% of Shots at Rim',\n",
    "'Average Influence Score',\n",
    "'Expected eFG%',\n",
    "'AutoStats FG% Defended',\n",
    "'AutoStats 3P% Defended',\n",
    "'Contested Jumper FG% Defended',\n",
    "'Uncontested Jumper FG% Defended',\n",
    "'% of Defended Jumpers Contested',\n",
    "'Contested 3P% Defended',\n",
    "'Uncontested 3P% Defended',\n",
    "'% of Defended 3s Contested',\n",
    "'Average Influence Score Defended',\n",
    "'Expected eFG% Defended',\n",
    "'Layup FG% Defended',\n",
    "'Passes/Touch',\n",
    "'Led to Shot %',\n",
    "'Assist %',\n",
    "'Secondary Assist %',\n",
    "'FT Assist %',\n",
    "'Offensive Adjusted Rebound %',\n",
    "'Offensive Contested Rebound %',\n",
    "'% of Offensive Rebounds Contested',\n",
    "'Defensive Adjusted Rebound %',\n",
    "'Defensive Contested Rebound %',\n",
    "'% of Defensive Rebounds Contested',\n",
    "'Crash & Boxout %',\n",
    "'Drives/Touch',\n",
    "'Player Points/Drive',\n",
    "'Team Points/Drive Chance',\n",
    "'Drives Defended/Defensive Chances',\n",
    "'Player Points/Drive Allowed',\n",
    "'Team Points/Drive Chance Allowed',\n",
    "'Isos/Touch',\n",
    "'Player Points/Iso',\n",
    "'Team Points/Iso Chance',\n",
    "'Isos Defended/Defensive Chances',\n",
    "'Player Points/Iso Allowed',\n",
    "'Team Points/Iso Chance Allowed',\n",
    "'Postups/Touch',\n",
    "'Player Points/Postup',\n",
    "'Team Points/Postup Chance',\n",
    "'Postups Defended/Defensive Chances',\n",
    "'Player Points/Postup Allowed',\n",
    "'Team Points/Postup Chance Allowed',\n",
    "'BH- Screens/Touch',\n",
    "'BH- Player Points/Screen',\n",
    "'BH- Team Points/Chance',\n",
    "'BH- Pass to Screener %',\n",
    "'BH- Screener Points/Touch',\n",
    "'BH Def- Ball Handler Points/Screen',\n",
    "'BH Def- Screens/Chance',\n",
    "'BH Def- Team Points/Chance',\n",
    "'BH Def- Ball Handler Pass to Screener %',\n",
    "'BH Def- Screener Points/Touch',\n",
    "'SC- Screens/Chance',\n",
    "'SC- Ball Handler Points/Screen',\n",
    "'SC- Points/Touch',\n",
    "'SC- Team Points/Chance',\n",
    "'SC- Combo Points/Screen',\n",
    "'SC Def- Ball Handler Points/Screen',\n",
    "'SC Def- Screens/Chance',\n",
    "'SC Def- Team Points/Chance',\n",
    "'SC Def- Ball Handler Pass to Screener %',\n",
    "'SC Def- Screener Points/Touch',\n",
    "'SC Def- Combo Points/Screen',\n",
    "'Closeout Touch %',\n",
    "'Points/Closeout Touch- Offense',\n",
    "'Team Points/Closeout Chance- Offense',\n",
    "'Closeouts/Chance',\n",
    "'Points/Closeout Allowed',\n",
    "'Team Points/Closeout Chance Allowed',\n",
    "'Full Closeout %',\n",
    "'Cutter- Screens/Chance',\n",
    "'Cutter- Team Points/Chance',\n",
    "'Cutter- Touches/Screen',\n",
    "'Cutter- Points/Touch',\n",
    "'Screener- Screens/Chance',\n",
    "'Screener- Team Points/Chance',\n",
    "'Screener- Cutter Touches/Screen',\n",
    "'Screener- Cutter Points/Touch',\n",
    "'Screener- Screener Touches/Screen',\n",
    "'Screener- Screener Points/Touch',\n",
    "'Cutter Def- Screens/Chance',\n",
    "'Cutter Def- Team Points/Chance',\n",
    "'Cutter Def- Cutter Touches/Screen',\n",
    "'Cutter Def- Cutter Points/Touch',\n",
    "'Cutter Def- Screener Touches/Screen',\n",
    "'Cutter Def- Screener Points/Touch',\n",
    "'Screener Def- Screens/Chance',\n",
    "'Screener Def- Team Points/Chance',\n",
    "'Screener Def- Cutter Touches/Screen',\n",
    "'Screener Def- Cutter Touch Points',\n",
    "'Screener Def- Screener Touches/Screen',\n",
    "'Screener Def- Screener Points/Touch',\n",
    "'Receiver- Handoffs/Touch',\n",
    "'Receiver- Points/Handoff',\n",
    "'Receiver- Team Points/Chance',\n",
    "'Setter- Handoffs/Touch',\n",
    "'Setter- Receiver Points/Handoff',\n",
    "'Setter- Team Points/Chance',\n",
    "'Receiver Defender- Handoffs/Chance',\n",
    "'Receiver Defender- Receiver Points/Handoff',\n",
    "'Receiver Defender- Team Points/Chance',\n",
    "'Setter Defender- Handoffs/Chance',\n",
    "'Setter Defender- Receiver Points/Handoff',\n",
    "'Setter Defender- Team Points/Chance',\n",
    "'Offensive Chances',\n",
    "'Defensive Chances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6e61a-a973-4cee-a10c-548285d229f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct = autostats_pct[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c99dcb-c9b4-4f22-ba39-4742fcf61d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename the player id \n",
    "autostats_pct = autostats_pct.rename({'Player ID':'PLAYER_ID'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397bbac-d0e6-4bda-9540-8856c3200269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset index\n",
    "autostats_pct.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191528e0-8212-485a-b12d-79238f10747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge to get only NBA caliber players \n",
    "autostats_pct = pd.merge(nba_players, autostats_pct, how='inner', on='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d95a11-a158-4821-8ef1-ab3fdfeee931",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa098a-3171-46fb-a51c-5db6f1a078e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611638a1-e9b7-4ee3-8e51-468e61944ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## grabs rows that are only from before someone started at the NBA \n",
    "## takes a while to run \n",
    "df = pd.DataFrame()\n",
    "for i in range(1, len(autostats_pct)):\n",
    "    if autostats_pct.loc[i, 'Season'] < autostats_pct.loc[i, 'START_SEASON']:\n",
    "        df = df.append(autostats_pct.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ae609-562e-45dd-be86-3a634e1b3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make it the new dataframe \n",
    "autostats_pct = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb894df6-898c-4721-8ef3-9a3ad7a41296",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56191c94-f795-4336-ae6b-fb51b3fa59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117960c-2f97-4af7-9fd6-cc522af302aa",
   "metadata": {},
   "source": [
    "### Need to drop columns\n",
    "\n",
    "columns = 1245 \n",
    "\n",
    "columns after rank is dropped (422-1243) = 424\n",
    "\n",
    "drop columns that are just totals = 301 + 5 (totals I need: 'PLAYER_ID', 'League ID', 'Team ID', 'Season', 'AutoStats Games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244a440-2f1c-4335-bcbe-a74183178999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autostats_pct = autostats_pct.drop(autostats_pct.iloc[:, 422:1243],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292e809-50b1-44a7-8282-414243cb04ce",
   "metadata": {},
   "source": [
    "Still need PLAYER_ID, League ID, Team ID, Season, AutoStats Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598bd11-b107-41c2-91da-87004b7ba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = list(pd.DataFrame(autostats_pct.dtypes[autostats_pct.dtypes != 'int64']).reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42458a-ae94-4153-9eaa-752a34f0399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd94aed-970f-45f9-9551-1993372720d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c6177-9b3a-47b6-8abc-01eaebc8ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autostats_pct = pd.concat([autostats_pct[['PLAYER_ID', 'League ID', 'Team ID', 'Season', 'AutoStats Games']], autostats_pct[cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5bec32-8d2d-4358-a1c7-a53646ddad1d",
   "metadata": {},
   "source": [
    "### Adding a column for drafted vs. undrafted \n",
    "`0` = NBA, non-drafted \n",
    "`1` = Drafted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e5179-0c96-477d-ad7d-7bc42866e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates column for drafted and undrafted \n",
    "autostats_pct['Drafted'] = np.where(autostats_pct['PICK_NUMBER'] == 'Undrafted', 'No', 'Yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dbda0-84f1-4f01-98c1-4d589ee78741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grab the ids, pick number and start season for later use \n",
    "pick_number = autostats_pct[['PLAYER_ID','PICK_NUMBER', 'START_SEASON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681e923-0f30-41f3-a722-cda5b5751852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## only want unique pairings \n",
    "pick_number = pick_number.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e70b31-7fe4-4819-b5db-1d4cc55df589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## send to a CSV \n",
    "pick_number.to_csv(\"pick_num_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fee5a0-f59b-4fc6-94b6-a0308a2e7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping unneeded columns\n",
    "autostats_pct = autostats_pct.drop(['START_SEASON'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38e67a-76bc-48b7-832c-c9111c13de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the Pick Number into the bins I created\n",
    "\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([1,2,3,4], '1-4'), inplace=True)\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([5,6,7,8], '5-8'), inplace=True)\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([9,10,11,12], '9-12'), inplace=True)\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([13,14,15,16,17,18], '13-18'), inplace=True)\n",
    "\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([19,20,21,22,23,24,25,26,27,28,29,30], '19-30'), inplace=True)\n",
    "autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60], '31-60'), inplace=True)\n",
    "#autostats_pct['PICK_NUMBER'].replace(dict.fromkeys([46,47,48,49,50,51,52,53,54,55,56,57,58,59,60], '46-60'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c2b97-c5ae-47d0-bab7-1ba783ce3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to convert the dashes in the data to NAs\n",
    "autostats_pct = autostats_pct.replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961c820-ef8b-4e92-93ba-cfd4952414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at how many NAs in each column \n",
    "\n",
    "na_values = list(autostats_pct.isna().sum())\n",
    "\n",
    "## add to bottom of dataframe\n",
    "autostats_pct.loc[len(autostats_pct)] = na_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693ee87-44f5-4abe-b7a4-d91bdab94797",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make NAs a dataframe \n",
    "na_values = pd.DataFrame(na_values)\n",
    "\n",
    "## look at how many NAs there are \n",
    "na_values[0].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27a8ef-6391-4feb-92a2-c4f80af78c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at which values have high nas\n",
    "# na_values = pd.DataFrame(autostats_pct.isna().sum()).reset_index()\n",
    "# na_values[na_values[0] > 50].sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84473f-97ea-40b9-b602-db05eed77698",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the columns with more than 100 NAs\n",
    "#autostats_pct = autostats_pct[autostats_pct.columns[autostats_pct.iloc[len(autostats_pct)-1] < 100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8fba4-dacc-4b61-b6ca-fa72c9fbad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## going to fill NAs with zeroes instead'\n",
    "autostats_pct = autostats_pct.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bc75c-5ac3-4495-b481-1244fef8a748",
   "metadata": {},
   "source": [
    "## Data Aggregation \n",
    "There are several rows for each player based on season. So, I am going to build an aggregated row where depending on how many games the player played in each season will determine the percent of that data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595449-df93-4259-af93-e72a124c0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the last row\n",
    "autostats_pct.drop(autostats_pct.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5bc81-c38d-409f-903a-88ad5d41f8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## creates a column to add back in later \n",
    "pick_number = autostats_pct['PICK_NUMBER']\n",
    "player_id = autostats_pct['PLAYER_ID']\n",
    "draft = autostats_pct['Drafted']\n",
    "season = autostats_pct['Season']\n",
    "#start = autostats_pct['START_SEASON']\n",
    "league = autostats_pct['League ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ae6e4-fe25-431c-8ea3-1137dd77df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sums up all AutoStats Games a player has \n",
    "a = autostats_pct.merge(pd.DataFrame(autostats_pct.groupby('PLAYER_ID') ['AutoStats Games'].sum()), on='PLAYER_ID')\n",
    "\n",
    "## creates a percentage of each player for each season\n",
    "autostats_pct['percent'] = (a['AutoStats Games_x']/a['AutoStats Games_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c603bf2-e1b6-4900-ac81-0eae1abec42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops columns that don't need to make floats \n",
    "autostats_pct = autostats_pct.drop(['PLAYER','PLAYER_ID','MAX_LEAGUE','PICK_NUMBER', 'Season', 'PLAYER', 'Drafted'], axis=1)\n",
    "autostats_pct = autostats_pct.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeae159-cbe7-4570-b36d-b06ba57dd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates the columns we need to multiple the percent by\n",
    "num_cols = autostats_pct.drop(['AutoStats Games'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6be66c-dfcd-4d4d-a271-1e3eeda25fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adds columns back in \n",
    "autostats_pct['PICK_NUMBER'] = pick_number\n",
    "autostats_pct['PLAYER_ID'] = player_id\n",
    "autostats_pct['Season'] = season\n",
    "autostats_pct['League ID'] = league\n",
    "#autostats_pct['START_SEASON'] = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225be64-3ac0-45dd-a159-0d82b5baa2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets the percent of each variable based on game\n",
    "for i in num_cols:\n",
    "    autostats_pct[i] = autostats_pct[i] * autostats_pct['percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fa248-24a2-407e-baf2-adf65bc34832",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add draft variable back in \n",
    "autostats_pct['Drafted'] = draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e90cad-441a-437c-9f0c-fba9c4bb1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a rank variable that gives rank to the player and season with the most recent season being 1 \n",
    "autostats_pct['rank'] = autostats_pct.groupby(['PLAYER_ID'])['Season'].rank('dense', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06c732-70f8-413a-a388-08ea9e5d5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = autostats_pct[['PLAYER_ID', 'Season','rank']]\n",
    "l[l['PLAYER_ID'] == 549961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cb981-060c-4b5e-b1de-76f53533df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a variable based on the rank to multiple the values\n",
    "percentage = []\n",
    "for i in range(0,len(autostats_pct)):\n",
    "    if autostats_pct.loc[i, 'League ID'] == 2:\n",
    "        if autostats_pct.loc[i, 'rank'] == 1: \n",
    "            percentage.append(2)\n",
    "        elif autostats_pct.loc[i, 'rank'] == 2: \n",
    "            percentage.append(3)\n",
    "        elif autostats_pct.loc[i, 'rank'] == 3: \n",
    "            percentage.append(5)\n",
    "        elif autostats_pct.loc[i, 'rank'] == 4: \n",
    "            percentage.append(5)\n",
    "        elif autostats_pct.loc[i, 'rank'] == 5: \n",
    "            percentage.append(5)\n",
    "        elif autostats_pct.loc[i, 'rank'] >= 6: \n",
    "            percentage.append(5)\n",
    "    else: \n",
    "        percentage.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e1eaa-6b02-4d14-968c-8596182d91c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## drop columns no longer needed \n",
    "num_cols.drop(['percent'], axis=1, inplace=True)\n",
    "autostats_pct.drop(['Season'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f39b8-3e2c-4472-b48e-9f506ab5683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure these are equal\n",
    "print(len(percentage))\n",
    "print(len(autostats_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7458c2-252f-4659-8e06-19b7dbef05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add value in \n",
    "autostats_pct['Rank_Value'] = percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d447ca-2548-4053-8da5-423961df2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiplies each row by its corresponding multiplier \n",
    "for i in num_cols:\n",
    "    autostats_pct[i] = autostats_pct[i] * autostats_pct['Rank_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec2d50-10d9-48fd-92e8-7919d9cc7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grab columns we will put in later \n",
    "cats = autostats_pct[['PLAYER_ID','PICK_NUMBER', 'Drafted', 'League ID']]\n",
    "cats = cats.groupby(['PLAYER_ID']).agg({'PICK_NUMBER':'first', 'Drafted':'first', 'League ID':'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c2db1-d775-44f3-809e-e140cb6d5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adds up the lines a single player has \n",
    "autostats_pct = autostats_pct.groupby(['PLAYER_ID']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e09128-3bb5-4fb5-9df6-96c959f1129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops unneeded columns\n",
    "autostats_pct.drop(['percent', 'rank', 'Rank_Value'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5736a-aead-442d-8f61-e295c4ddc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adds needed columns back in \n",
    "autostats_pct = pd.merge(autostats_pct, cats, how='inner', on='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e9320-f2f7-4c2b-bda4-84a71156a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct = autostats_pct.drop(['League ID_x', 'League ID_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a7546-f515-4e76-aa5c-e7095559b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "autostats_pct.to_csv('autostats_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26556cb-f1e8-4db9-8047-2774397d82b5",
   "metadata": {},
   "source": [
    "# Exploring Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c74310-54f7-4433-b288-817deee2c9ce",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94ad3b-e721-444f-827a-939301f0b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = autostats_pct.drop(['PICK_NUMBER', 'PLAYER_ID', 'percent', 'Drafted'], axis=1)\n",
    "y_full = autostats_pct['PICK_NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61cec7-1a6e-42b7-89ae-3ee72ffead1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_full.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d7bd8-3e78-4023-86e8-c9e4306be7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87582fa6-c8e2-4eac-8ce3-d0de3e53f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features \n",
    "X_pct = X_full.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c065dc-f102-4dbd-94a3-e8a59f63a045",
   "metadata": {},
   "source": [
    "## Oversampling \n",
    "\n",
    "Do we do PCA or SMOTE first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cbb9f-0ee1-4ee2-84de-4c2428a381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94b5b0-8b2d-4d98-b6c5-64c469cfb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the data \n",
    "X_pct=(X_pct-X_pct.mean())/(X_pct.max()-X_pct.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7de869-49af-4018-82ff-6287bc053670",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = y_full.astype('string')\n",
    "X_pct = X_pct.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bba77a-649a-4239-abca-2f7f2205642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels as integers for y_train \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_full)\n",
    "y_full = encoder.transform(y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e51431-c6ef-43b3-8e6b-c98bf8389fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6367076-c803-4f93-a301-b6f75cdc7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_mapping = {l: i for i, l in enumerate(encoder.classes_)}\n",
    "integer_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e22ccd-c7c7-4fc7-a96f-21a3d391eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting with new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pct, y_full, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea031a1-1286-4823-ab81-5855d837d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)+len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7624bb5-927e-4563-b5f2-5928d15108d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5053f2-5cad-4268-bb4f-bff2b58b4a81",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a0cb8-f8cb-414e-b265-b7f30b74d091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize distribution of y train data \n",
    "# counter = Counter(y_train)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_train) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91eb576-52ad-481b-964d-4c2b72f35a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset of the x train to level the y trains\n",
    "# oversample = SMOTE()\n",
    "# X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "# # summarize distribution\n",
    "# counter = Counter(y_train)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_train) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b830d2c-c1e8-461c-abd6-16556bd8619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize distribution of y test data \n",
    "# counter = Counter(y_test)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_test) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc9b83-b82e-4c69-a446-8df27e88b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform the dataset of the x test to level the y test\n",
    "# oversample = SMOTE()\n",
    "# X_test, y_test = oversample.fit_resample(X_test, y_test)\n",
    "# # summarize distribution\n",
    "# counter = Counter(y_test)\n",
    "# for k,v in counter.items():\n",
    "#     per = v / len(y_test) * 100\n",
    "#     print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# pyplot.bar(counter.keys(), counter.values())\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601c894-57ba-4a88-b846-01a085f527c8",
   "metadata": {},
   "source": [
    "SMOTE & Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f13a5-df4b-4164-baa3-e17b33363c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.title('Train Data Counts before Resampling')\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=888)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_resampled)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_resampled) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.title('Train Data Counts before Resampling')\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7266e91-0de0-4b04-a355-9faab66265f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_test)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_test) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.title('Test Data Counts before Resampling')\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=888)\n",
    "X_test_resampled, y_test_resampled = smote_tomek.fit_resample(X_test, y_test)\n",
    "\n",
    "counter = Counter(y_test_resampled)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_test_resampled) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.title('Test Data Counts After Resampling')\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4de58e-a006-4ca8-9dbe-ea2b41e5323c",
   "metadata": {},
   "source": [
    "### Model for drafted vs. non-drafted NBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c058888-a8d4-47d2-85e9-a00275c3fc7f",
   "metadata": {},
   "source": [
    "First, Need to create a variable for drafted vs. non-drafted\n",
    "\n",
    "`0` = NBA, non-drafted \n",
    "`1` = Drafted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445cc0a-0584-4c59-a9dc-095e5ebe8082",
   "metadata": {},
   "source": [
    "Model Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391b46c-06b2-4330-9681-d76d309695de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rank = autostats_pct.drop(['PICK_NUMBER', 'PLAYER_ID'], axis=1)\n",
    "# Y_pct = autostats_pct['PICK_NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f439a-3be3-4ce4-b054-01a47aea5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NAs with mean \n",
    "#X_rank = X_rank.fillna(X_rank.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4167d3d-a57f-41aa-940f-e755e1124411",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't need this unless we are not doing the aggregated data \n",
    "# X_rank = X_rank.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7402f-71c8-4a23-8c36-1f192b092400",
   "metadata": {},
   "source": [
    "Don't need this since we already dropped it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d098fa-e233-42ef-8dfc-091a5cb63efc",
   "metadata": {},
   "source": [
    "#### PCA \n",
    "\n",
    "need to normalize first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7728c-aaf3-41ef-a38c-650194459857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all = PCA(n_components=len(X_train_resampled.columns))\n",
    "pca_all.fit(X_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581630b3-07e4-4c6f-87cc-64bc58f485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(np.cumsum(pca_all.explained_variance_ratio_ * 100))\n",
    "plt.xlabel('Number of components')\n",
    "plt.xlim([0, 200])\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb782f-426b-4f4d-bedc-d1b9b093e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test sets\n",
    "pca_100 = PCA(n_components=100)\n",
    "pca_100.fit(X_train_resampled)\n",
    "X_train_reduced = pca_100.transform(X_train_resampled)\n",
    "X_test_reduced = pca_100.transform(X_test_resampled)\n",
    "\n",
    "# verify shape after PCA\n",
    "print(\"Shape:\", X_train_resampled.shape)\n",
    "print(\"Test images shape: \", X_test_resampled.shape)\n",
    "\n",
    "# get exact variability retained\n",
    "print(\"\\nVar retained (%):\", \n",
    "      np.sum(pca_100.explained_variance_ratio_ * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa5e57-d2d1-4dec-8f39-913f3eb9be4c",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635008d1-aec5-4d54-bcfa-6659b37f59ee",
   "metadata": {},
   "source": [
    "`0` : '1-4'\n",
    "\n",
    "`1`: '13-18'\n",
    "\n",
    "`2`: '19-30'\n",
    "\n",
    "`3`: '31-60'\n",
    "\n",
    "`4`: '5-8'\n",
    "\n",
    "`5`: 9-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e53fb-ee9d-4260-b147-8c4d7924dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train_reduced, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b6cb6-cdfd-4859-b472-a5765edd9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = forest.predict(X_test_reduced)\n",
    "\n",
    "# View accuracy score\n",
    "accuracy_score(y_test_reduced, predictions)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(classification_report(y_test_resampled, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005c025-ca77-4956-b28b-f1b701e6ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_resampled, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69280c-6a29-4a3c-ac73-2a694ec6ec5f",
   "metadata": {},
   "source": [
    "***Problem:*** it is only guessing one category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f114a6-1917-4874-93ab-078d9d230911",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Penalized-SVM \n",
    "*** Don't Actually need this anymore since we oversampled ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87a53f-e478-4b12-8c6f-fb02ae37d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "\n",
    "# we can add class_weight='balanced' to add panalize mistake\n",
    "svc_model = SVC(class_weight='balanced', probability=True)\n",
    "\n",
    "svc_model.fit(X_train_reduced, y_train)\n",
    "\n",
    "svc_predict = svc_model.predict(X_test_reduced)# check performance\n",
    "#print('ROCAUC score:',roc_auc_score(y_test, svc_predict))\n",
    "print('Accuracy score:',accuracy_score(y_test, svc_predict))\n",
    "#print('F1 score:',f1_score(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e9b77-eaf6-484d-b6ff-3e04db14f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee1b24-9f23-48ce-9783-3dc3f1e11e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b12259-57d3-4c2b-b2b5-75ec470fef8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Random Forest with Balanced Weights\n",
    "*** Don't Actually need this anymore since we oversampled ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7a741-f2f1-483c-89fb-778f45e5d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model and fitting it \n",
    "balanced_rf = RandomForestClassifier(class_weight='balanced', random_state=0, n_jobs=-1).fit(X_train_resampled, y_train)\n",
    "\n",
    "# Baseline model prediction\n",
    "y_test_pred_balanced = balanced_rf.predict(X_test_reduced)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(classification_report(y_test, y_test_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d53964-b949-4cc6-b27c-9251fea5a766",
   "metadata": {},
   "source": [
    "Support Vector Machines do a better job of helping with imbalanced data even thought the random forest has a higher accuracy but that is just because it is only guessing two categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a8860-ef05-405a-bafb-c6d436648289",
   "metadata": {},
   "source": [
    "## Artifical Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c21eb1-2ae6-4d01-bdfb-00c940e5adbe",
   "metadata": {},
   "source": [
    "- '1-4': `0`\n",
    "- '5-8': `4`\n",
    "- '9-12': `5`\n",
    "- '13-18': `1`\n",
    "- '19-30': `2`\n",
    "- '31-60': `3`\n",
    "- 'Other- NBA': `6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed285d-b5e0-489c-929d-3fdba812f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68d686-f253-4766-9f18-91112b039073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5c67a-427b-418c-85dd-1357bc63f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abc21d-ff08-4f51-957e-be9b0de76d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## allows you to see which categorical value it is \n",
    "# list(encoder.inverse_transform(encoded_Y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f3883-b4c2-4fe0-9dfd-b6334efc4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e29e7f-1f3c-4a64-b2a5-40a68764139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a6a2e-2e42-430a-b95c-6ae27609e4be",
   "metadata": {},
   "source": [
    "#### One Way to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811fb80-1f17-48f0-824f-945e7c4399b9",
   "metadata": {},
   "source": [
    "Need to create class weights since it is predicting only one class the whole time \n",
    "\n",
    "`0` : '1-4'\n",
    "\n",
    "`1`: '13-18'\n",
    "\n",
    "`2`: '19-30'\n",
    "\n",
    "`3`: '31-60'\n",
    "\n",
    "`4`: '5-8'\n",
    "\n",
    "`5`: 9-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e174a-bc4e-41c3-855d-f7f8d22665d4",
   "metadata": {},
   "source": [
    "*** Don't really need class weights anymore either ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26837793-9bc3-48c3-b4f4-aff83f951f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(X_train_reduced.shape[1],), activation='relu')) # input shape is (features,)\n",
    "model.add(Dense(25, activation='softmax'))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345dfa3f-ce65-4c2e-95f5-b06b9ec31824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) \n",
    "\n",
    "# now we just update our model fit call\n",
    "history =  model.fit(X_train_reduced,\n",
    "                    dummy_y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=5000, \n",
    "                    # class_weight = class_weights,\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f460e-7ae5-41b9-a8b7-dcb00338d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac3b15-e121-4232-b174-fd4634c2ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_train_reduced) # see how the model did!\n",
    "print(preds[4]) # i'm spreading that prediction across three nodes and they sum to 1\n",
    "print(np.sum(preds[0])) # sum it up! Should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edff3fe-dbab-487b-a23f-c38525d52997",
   "metadata": {},
   "source": [
    "This is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6dc0d-106d-48e2-8564-3dee276771e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb752f8-8399-420d-a319-fc5e4c773c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_resampled, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802961f-7b86-4ad1-b19d-69f4fb15ee7b",
   "metadata": {},
   "source": [
    "`0` : '1-4'\n",
    "\n",
    "`1`: '13-18'\n",
    "\n",
    "`2`: '19-30'\n",
    "\n",
    "`3`: '31-60'\n",
    "\n",
    "`4`: '5-8'\n",
    "\n",
    "`5`: 9-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5260f-6f05-4278-8f0f-d23834d450a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12', 'Other']); ax.yaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12', 'Other']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be67892-b740-4092-ad52-3beef65b9201",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix we can see that for most of the labels we are good in the 40% while for 19-30 there are no predictions but seem to be close to the 31-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866d624-256e-4a03-9f43-ee735a4dedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7467c-9e41-4bfe-9986-3c0866f81f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd97613-631f-4933-a96a-3ed9a9e54205",
   "metadata": {},
   "source": [
    "#### Another Way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafedef-bcb1-4930-9f3f-5f456ef76b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(16, input_dim=100, activation='relu'))\n",
    "model2.add(Dense(12, activation='relu'))\n",
    "model2.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc8af9-85d8-441e-be7b-615f621d42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f625144-4a74-4cc6-825e-7fc441d7d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train_reduced, dummy_y_train, epochs=100, batch_size=64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1629c-dca0-48a1-b4f7-ded91a4780ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test_reduced)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(dummy_y_test)):\n",
    "    test.append(np.argmax(dummy_y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eef211-78f2-414b-a09b-730b080f0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019dba0-3bf7-4fe2-928f-674bdba6ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train_reduced, dummy_y_train, validation_data = (X_test_reduced,dummy_y_test), epochs=100,batch_size=64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d26c2f-1023-4135-afbe-84d69eb73f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba0014-ad3f-43a5-a294-ce114120487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e129c-2bcd-46ba-ab6d-4768891ed419",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_resampled, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f70ad-a959-4956-9a92-c47ef9427883",
   "metadata": {},
   "source": [
    "Maybe try bootstrapping???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8d2f7-e555-4800-ad5f-12346f884c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
