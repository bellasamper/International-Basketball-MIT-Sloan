{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048b7f98-01a0-4642-b410-4cfbe58c64c5",
   "metadata": {},
   "source": [
    "# Box Score Data (Step Two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0dc4-9388-43b9-b84a-4514412b8a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LassoCV\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ca582-8195-4cb2-90b5-6dcda0c5d551",
   "metadata": {},
   "source": [
    "## Understanding Box Score data \n",
    "- each line is a game associated with a player \n",
    "- season ID, Team ID, Player ID, Team Name, leagueID, confID\n",
    "- do not have a lot of info for international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e577366-506d-4ad8-9f9c-206b6c9e72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box score data for all the possible players in US\n",
    "box_data = pd.read_csv(\"Box Score Aggregates.csv\")\n",
    "\n",
    "# Box score data for international players \n",
    "intern_data = pd.read_excel(\"International Stats.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d6e6b-fc21-4796-b6c1-6b6b957ec1ee",
   "metadata": {},
   "source": [
    "### Changing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e446493-f4d9-42e4-b747-d3f36a025b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings(df_aggregated):\n",
    "    df_aggregated['FGM_30']=(30*df_aggregated['FGM']/df_aggregated['MP'])\n",
    "    df_aggregated['FGA_30']=(30*df_aggregated['FGA']/df_aggregated['MP'])\n",
    "    df_aggregated['TPM_30']=(30*df_aggregated['TPM']/df_aggregated['MP'])\n",
    "    df_aggregated['TPA_30']=(30*df_aggregated['TPA']/df_aggregated['MP'])\n",
    "    df_aggregated['FTM_30']=(30*df_aggregated['FTM']/df_aggregated['MP'])\n",
    "    df_aggregated['FTA_30']=(30*df_aggregated['FTA']/df_aggregated['MP'])\n",
    "    df_aggregated['FOULS_30']=(30*df_aggregated['PERSONAL_FOULS']/df_aggregated['MP'])\n",
    "    df_aggregated['BLOCKS_30']=(30*df_aggregated['BLOCKS']/df_aggregated['MP'])\n",
    "    df_aggregated['STEALS_30']=(30*df_aggregated['STEALS']/df_aggregated['MP'])\n",
    "    df_aggregated['ASSISTS_30']=(30*df_aggregated['ASSISTS']/df_aggregated['MP'])\n",
    "    df_aggregated['OREB_30']=(30*df_aggregated['OREB']/df_aggregated['MP'])\n",
    "    df_aggregated['DREB_30']=(30*df_aggregated['DREB']/df_aggregated['MP'])\n",
    "    df_aggregated['TOV_30']=(30*df_aggregated['TURNOVERS']/df_aggregated['MP'])\n",
    "    df_aggregated['FG_PCT']=(df_aggregated['FGM']/df_aggregated['FGA'])\n",
    "    df_aggregated['TP_PCT']=(df_aggregated['TPM']/df_aggregated['TPA'])\n",
    "    df_aggregated['FT_PCT']=(df_aggregated['FTM']/df_aggregated['FTA'])\n",
    "    df_aggregated['USG']=(df_aggregated['USAGE_NUMERATOR']/df_aggregated['USAGE_DENOMINATOR'])\n",
    "    df_aggregated['ASSIST_PCT']=(df_aggregated['ASSISTS']/df_aggregated['ASSIST_PCT_DENOM'])\n",
    "    df_aggregated['BLOCK_PCT']=(df_aggregated['BLOCK_PCT_NUM']/df_aggregated['BLOCK_PCT_DENOM'])\n",
    "    df_aggregated['OREB_PCT']=(df_aggregated['OREB_PCT_NUM']/df_aggregated['OREB_PCT_DENOM'])\n",
    "    df_aggregated['DREB_PCT']=(df_aggregated['DREB_PCT_NUM']/df_aggregated['DREB_PCT_DENOM'])\n",
    "    df_aggregated['STL_PCT']=(df_aggregated['STL_PCT_NUM']/df_aggregated['STL_PCT_DENOM'])\n",
    "    df_aggregated['TOV_PCT']=(df_aggregated['TURNOVERS']/df_aggregated['TOV_PCT_DENOM'])\n",
    "   \n",
    "    return df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c6eca-c074-4c05-822c-d64ed8d32986",
   "metadata": {},
   "outputs": [],
   "source": [
    "intern_data = ratings(intern_data)\n",
    "intern_data['FTM_Rate']=(intern_data['FTM']/intern_data['FGA'])\n",
    "box_data['FTM_Rate']=(box_data['FTM']/box_data['FGA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5a6bb-bfd7-4a1a-9687-e8f84b9ccbad",
   "metadata": {},
   "source": [
    "### Making the Data Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1067bec-1d6c-4370-b1ff-c5bd2871b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "intern_data.rename({'Player ID': 'PLAYER_ID'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f428f-d034-4e0b-9608-bce7e6240d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = list(box_data.columns)\n",
    "intern = list(intern_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e7180-6a0e-46fa-8f14-ddb45f33dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at difference between the columns\n",
    "intern_drop = list(set(intern) - set(box))\n",
    "box_drop = list(set(box) - set(intern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a1e25-f387-432c-b99e-cdb6b100dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intern_data = intern_data.drop(intern_drop, axis=1)\n",
    "box_data = box_data.drop(box_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d820174-6cc4-4fe6-a66b-04e7a82a77a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## need to add these back in \n",
    "intern_data = intern_data[['PLAYER_ID','SEASON','PLAYER_GAMES', 'FGM_30','FGA_30','TPM_30','TPA_30','FTM_30','FTA_30',\n",
    "                          'FOULS_30','BLOCKS_30','STEALS_30','ASSISTS_30','OREB_30','DREB_30',\n",
    "                          'TOV_30','FG_PCT','TP_PCT','FT_PCT','USG','ASSIST_PCT','BLOCK_PCT','OREB_PCT',\n",
    "                          'DREB_PCT','FTM_Rate','STL_PCT','TOV_PCT']]\n",
    "box_data = box_data[['PLAYER_ID','SEASON','PLAYER_GAMES', 'FGM_30','FGA_30','TPM_30','TPA_30','FTM_30','FTA_30',\n",
    "                    'FOULS_30','BLOCKS_30','STEALS_30','ASSISTS_30','OREB_30','DREB_30',\n",
    "                    'TOV_30','FG_PCT','TP_PCT','FT_PCT','USG','ASSIST_PCT','BLOCK_PCT','OREB_PCT',\n",
    "                    'DREB_PCT','FTM_Rate','STL_PCT','TOV_PCT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba575b-2b66-40ed-b7fc-f17bff858b38",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8478b07-e4e6-45a3-8244-11f36685f990",
   "metadata": {},
   "source": [
    "### Get NBA Players for Both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed0286-41f0-47eb-b7b4-f882755a7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reads the autostats player_id data in \n",
    "nba = pd.read_csv(\"pick_num_data.csv\").drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8237c4e-e0a7-4f3b-975c-7b88004855a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6591cf-d10c-454c-b094-1981cb28cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba2 = pd.read_csv('NBA Caliber Players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef272b73-0803-4807-baf6-9ea65005f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba2['PLAYER'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db23cc-3ef3-4458-bf0f-7a2455f96903",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making sure start season is right \n",
    "nba2 = nba2[nba2['START_SEASON'] > 2012]\n",
    "\n",
    "## grabbing only columns needed \n",
    "nba2 = nba2[['PLAYER_ID', 'START_SEASON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854de86-fb3b-4cd6-8534-c27e1d1cc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10593a6e-800c-424b-862e-1bab0875af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging the nba players with the box data to get only the players of NBA caliber \n",
    "box_data = pd.merge(nba2, box_data, how='inner', on='PLAYER_ID')\n",
    "\n",
    "intern_data = pd.merge(nba2, intern_data, how='inner', on='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec35246-695a-49fa-b80f-13ea92a21c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197162c-3650-4c98-b045-f79a9b5ac302",
   "metadata": {},
   "outputs": [],
   "source": [
    "intern_data['PLAYER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0005b-4746-4828-8067-73950d42e517",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aggregating each Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923927a-718c-430e-9309-c885ecd7fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sums the columns based on player id and season to get a sum of the overall season \n",
    "box_data = pd.DataFrame(box_data.groupby(['PLAYER_ID', 'START_SEASON']).agg('sum').reset_index())\n",
    "\n",
    "intern_data = pd.DataFrame(intern_data.groupby(['PLAYER_ID', 'START_SEASON']).agg('sum').reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a78b05-d719-4c82-a2f5-0d95c7e341fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sums the columns based on player id and season to get a sum of the overall season \n",
    "# box_data = pd.DataFrame(box_data.groupby(['PLAYER_ID', 'SEASON','PICK_NUMBER','START_SEASON']).agg('sum').reset_index())\n",
    "\n",
    "# intern_data = pd.DataFrame(intern_data.groupby(['PLAYER_ID', 'SEASON','PICK_NUMBER', 'START_SEASON']).agg('sum').reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04053e56-a701-4245-a958-7e958c692029",
   "metadata": {},
   "outputs": [],
   "source": [
    "## columns that need an average\n",
    "cols = box_data.drop(['PLAYER_ID', 'SEASON', 'START_SEASON'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c65c98-0622-4717-8f3b-72435ebd4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data = box_data.astype('float')\n",
    "\n",
    "intern_data = intern_data.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76298b-2a7a-4bed-b89f-28565aae6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting an average for each column \n",
    "for i in cols: \n",
    "    box_data[i] = box_data[i]/box_data['PLAYER_GAMES']\n",
    "    \n",
    "## getting an average for each column \n",
    "for i in cols: \n",
    "    intern_data[i] = intern_data[i]/intern_data['PLAYER_GAMES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38833d-0e4b-4c89-bcbc-cb207e1aba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a percentage of each player for each season/league \n",
    "a = box_data.merge(pd.DataFrame(box_data.groupby('PLAYER_ID') ['PLAYER_GAMES'].sum()), on='PLAYER_ID')\n",
    "box_data['percent'] = (a['PLAYER_GAMES_x']/a['PLAYER_GAMES_y'])\n",
    "\n",
    "## creates a percentage of each player for each season/league \n",
    "a2 = intern_data.merge(pd.DataFrame(intern_data.groupby('PLAYER_ID') ['PLAYER_GAMES'].sum()), on='PLAYER_ID')\n",
    "intern_data['percent'] = (a2['PLAYER_GAMES_x']/a2['PLAYER_GAMES_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d5b1e-b1a0-46c7-9fc7-4cf2a3ae28ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## columns that need to be multiplied \n",
    "num_cols = box_data.drop(['PLAYER_ID', 'SEASON', 'START_SEASON', 'PLAYER_GAMES', 'percent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dae87f-ae3a-4c92-a766-4f845535310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets the value based on percent of each variable based on game\n",
    "for i in num_cols:\n",
    "    box_data[i] = box_data[i] * box_data['percent']\n",
    "    \n",
    "## gets the value based on percent of each variable based on game\n",
    "for i in num_cols:\n",
    "    intern_data[i] = intern_data[i] * intern_data['percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2670faa-c0fe-4e9d-ac96-ed6172029586",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a rank variable that gives rank to the player and season with the most recent season being 1 \n",
    "box_data['rank'] = box_data.groupby(['PLAYER_ID'])['SEASON'].rank('dense', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85f98f-4b1c-49ea-8d73-58e399faa75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a variable based on the rank to multiple the values\n",
    "percentage = []\n",
    "for i in range(0,len(box_data)):\n",
    "    if box_data.loc[i, 'rank'] == 1: \n",
    "            percentage.append(2)\n",
    "    elif box_data.loc[i, 'rank'] == 2: \n",
    "            percentage.append(3)\n",
    "    elif box_data.loc[i, 'rank'] == 3: \n",
    "            percentage.append(5)\n",
    "    elif box_data.loc[i, 'rank'] == 4: \n",
    "            percentage.append(5)\n",
    "    elif box_data.loc[i, 'rank'] == 5: \n",
    "            percentage.append(5)\n",
    "    elif box_data.loc[i, 'rank'] >= 6: \n",
    "            percentage.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75096a72-644e-4444-8d81-124fcb491064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## double checks the length\n",
    "print(len(percentage))\n",
    "print(len(box_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd68fa-df36-400e-a658-91f810a27998",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adds percent into the data \n",
    "box_data['Rank_Value'] = percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff5ea7-a55f-4a41-a4c0-b1dbc675c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates the columns needed to multiple the value by \n",
    "num_col = box_data.drop(['PLAYER_ID', 'SEASON', 'PLAYER_GAMES', 'rank'], axis=1)\n",
    "\n",
    "## multiplies each row by its corresponding multiplier \n",
    "for i in num_col:\n",
    "    box_data[i] = box_data[i] * box_data['Rank_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65334e75-6bb5-4478-8c8c-f06b190f3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba2 = pd.read_csv('NBA Caliber Players.csv')\n",
    "NBA = nba2[['PLAYER_ID', 'PICK_NUMBER']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad3471-96ad-41a4-a0de-645d923562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grab columns we will put in later \n",
    "# cats = box_data[['PLAYER_ID','PICK_NUMBER']]\n",
    "# cats = box_data.groupby(['PLAYER_ID']).agg({'PICK_NUMBER':'first'}).reset_index()\n",
    "\n",
    "# ## grab columns we will put in later \n",
    "# cats2 = intern_data[['PLAYER_ID','PICK_NUMBER']]\n",
    "# cats2 = intern_data.groupby(['PLAYER_ID']).agg({'PICK_NUMBER':'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599a379-8826-4b25-835f-b688ea951074",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unneeded columns \n",
    "box_data.drop(['SEASON', 'percent', 'rank', 'Rank_Value', 'START_SEASON'], axis=1, inplace=True)\n",
    "\n",
    "## drop unneeded columns \n",
    "intern_data.drop(['SEASON', 'percent', 'START_SEASON'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf206c5-be8c-4859-87b3-83b9b5282de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sums up the variables based on player for an aggregation\n",
    "box = box_data.groupby(['PLAYER_ID'], as_index=False).agg('sum')\n",
    "international = intern_data.groupby(['PLAYER_ID'], as_index=False).agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c39470-99b0-4898-ad0f-d0de23bee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adds needed columns back in \n",
    "box = pd.merge(box, NBA, how='inner', on='PLAYER_ID')\n",
    "\n",
    "## adds needed columns back in \n",
    "international = pd.merge(international, NBA, how='inner', on='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d50302-79ea-458a-ba85-c8446ff56a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combining International and US "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fb1a7-7cd4-4925-946f-2330f909c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(box) + len(international)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889565b9-8b41-420b-8902-be7727176bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([box, international], axis=0)\n",
    "combined = combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686b154-aceb-49f8-b1dd-54dbb6e56493",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('box_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7de55-bc9b-4f10-9339-8291f8f49fb5",
   "metadata": {},
   "source": [
    "## Set up data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d531211-f080-4654-b279-900b857570cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['PICK_NUMBER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301b867-4109-4337-a6b6-0ed642ab4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the Pick Number into the bins \n",
    "\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([1,2,3,4], '1-4'), inplace=True)\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([5,6,7,8], '5-8'), inplace=True)\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([9,10,11,12], '9-12'), inplace=True)\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([13,14,15,16,17,18], '13-18'), inplace=True)\n",
    "\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([19,20,21,22,23,24,25,26,27,28,29,30], '19-30'), inplace=True)\n",
    "combined['PICK_NUMBER'].replace(dict.fromkeys([31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60], '31-60'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e4c78-f9b1-4e90-a5b4-2fab02f67ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['PICK_NUMBER'] = combined['PICK_NUMBER'].fillna('Undrafted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151d3d7-fd19-4b04-8834-81591b1b00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"box_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdfed3-f84d-41a0-b7c0-48f8d0cd716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = college_box.drop(['PICK_NUMBER', 'PLAYER_ID'], axis=1)\n",
    "y = college_box['PICK_NUMBER']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2701b9-9b03-402b-af42-776a0918fbf3",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f117a-4da6-449d-8c31-92e57799dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the data \n",
    "X=(X-X.mean())/(X.max()-X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab622-0a04-43b7-a2bb-ccf47330d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting with new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True) \n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636f925-3f15-462f-80ac-8c980d00f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all = PCA(n_components=22)\n",
    "pca_all.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0f59a-ab28-4dec-b787-4189b2a71fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(np.cumsum(pca_all.explained_variance_ratio_ * 100))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e00bd1-c05a-486b-b89f-3287e8632006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test sets\n",
    "pca_10 = PCA(n_components=10)\n",
    "pca_10.fit(X_train)\n",
    "X_train_reduced = pca_10.transform(X_train)\n",
    "X_test_reduced = pca_10.transform(X_test)\n",
    "\n",
    "# verify shape after PCA\n",
    "print(\"Shape:\", X_train_reduced.shape)\n",
    "print(\"Test images shape: \", X_test_reduced.shape)\n",
    "\n",
    "# get exact variability retained\n",
    "print(\"\\nVar retained (%):\", \n",
    "      np.sum(pca_10.explained_variance_ratio_ * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910be82-7410-4d8b-9c1b-f711cf84b271",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e1dc4-b6fb-4f6e-97ae-345d6275262b",
   "metadata": {},
   "source": [
    "### W/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa8e5c-151b-4db9-b9a4-826db0679bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4719d5-5d17-4a5f-a1be-6906ad674e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('string').sort_values()\n",
    "y_test = y_test.astype('string').sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb4340-9925-4bb6-aed9-b5c971f57d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels as integers for y_train \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f584f-b24e-41c4-a5b8-f5a3ed098246",
   "metadata": {},
   "outputs": [],
   "source": [
    "## allows you to see which categorical value it is \n",
    "list(encoder.inverse_transform(encoded_Y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93503f-7c06-47b1-ab2c-9a09d7dad307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels as integers for y_test \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c589b4-747f-4d2e-a695-d5e5dcdeb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/y_train.value_counts()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d7e92-b390-4df7-9c07-d915dc441f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced', classes = np.unique(y_train)\n",
    "                                               , y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e62d32-c67e-4d49-adfa-274c3e517ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b19407-7685-41f3-812b-9f070b3e8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 2.83333333, 1:1.56578947, 2: 0.81506849, 3: 0.33426966, 4: 2.83333333, 5:2.28846154}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0bb25-00e7-44e1-a164-383015c50895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = {0: 3.448276, 1: 2.5, 2:1.449275, 3: 0.625, 4: 5.0, 5: 3.571429, 6:0.104493}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02acbb6-b7ff-4d1d-8a50-58fcda71ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(X_train_reduced.shape[1],), activation='relu')) # input shape is (features,)\n",
    "#model.add(Dense(25, activation='softmax'))\n",
    "#model.add(Dense(16, activation='softmax'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd88a7-742f-45d7-add2-92db4df842b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) \n",
    "\n",
    "# now we just update our model fit call\n",
    "history =  model.fit(X_train_reduced,\n",
    "                    dummy_y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=1000, \n",
    "                    class_weight = class_weights,\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef0fd5-a5f6-4dc1-8212-2d8da747a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ab1c9-6793-49d8-bb08-8ff51b5984b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_train_reduced) # see how the model did!\n",
    "print(preds[4]) # i'm spreading that prediction across three nodes and they sum to 1\n",
    "print(np.sum(preds[0])) # sum it up! Should be 1\n",
    "\n",
    "predictions = preds.argmax(axis=1)\n",
    "\n",
    "cm = confusion_matrix(encoded_Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f9c8d-9400-488a-89b3-c1faa1be8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12']); ax.yaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9479d-320a-4602-afa8-93428d7f1130",
   "metadata": {},
   "source": [
    "### W/o PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dfad7-93fa-4b4d-b5a1-258184c05ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train)\n",
    "X_test_array = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff26760-9173-446c-b8ef-e39a2a9c82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(22, input_shape=(X_train_array.shape[1],), activation='relu')) # input shape is (features,)\n",
    "#model.add(Dense(25, activation='softmax'))\n",
    "#model.add(Dense(16, activation='softmax'))\n",
    "model2.add(Dense(6, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545bb10-9750-4003-98c4-8ffa3b2eca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) \n",
    "\n",
    "# now we just update our model fit call\n",
    "history =  model2.fit(X_train_array,\n",
    "                    dummy_y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=5000, \n",
    "                    class_weight = class_weights,\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82388828-b2d3-45b4-8845-7cab890efff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800190-7db6-4b44-876b-590ab79ca5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12']); ax.yaxis.set_ticklabels(['1-4', '13-18', '19-30', '31-60', '5-8', '9-12']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f195fb-9dc9-425d-981e-709eba851a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
